{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Translator 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwefJZOS_5MF"
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXFP0z6OYxMR",
        "outputId": "1def8345-1d16-4e99-e18e-2c6e9d4c9de4"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jun 28 11:33:18 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   43C    P0    26W /  70W |   1592MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4lU4qFU_5MI"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuT8mE2U_5MI"
      },
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    #s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    #s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eS9ol66_5MJ"
      },
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')[0:2]] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g84PCv4k_5MJ"
      },
      "source": [
        "#lines1 = open('%s-%s.txt' % ('eng', 'hin'), encoding='utf-8').\\\n",
        " #       read().strip().split('\\n')\n",
        "#lines1[0].split('\\t')[0:2]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjgVZhhv_5MK"
      },
      "source": [
        "MAX_LENGTH = 30\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ1VbGwu_5MK",
        "outputId": "7547b4f4-9310-4994-974e-a9af0a33ceff"
      },
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    #pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence((pair[0]))\n",
        "        output_lang.addSentence((pair[1]))\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "\n",
        "input_lang, output_lang, pairs = prepareData('eng', 'hin', False)\n",
        "print(random.choice(pairs))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 2948 sentence pairs\n",
            "Trimmed to 2948 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "eng 2789\n",
            "hin 3148\n",
            "['The king was deprived of his power .', 'उस राजा से उसकी ताक़त छीन ली गई।']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtUalXLi_5ML"
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iufE7yDa_5ML"
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yyd3BLhJ_5MM"
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xKFN3Od_5MN"
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAhn5wSq_5MN"
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3b2KnMm_5MO"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ERyBU-z_5MO"
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOS4tiYy_5MO"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vCGfLpy_5MP"
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RguQfPRr_5MP"
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqwX4vQp_5MP",
        "outputId": "fff9d375-250f-4c49-ccfd-16a2c70b7a8d"
      },
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 400000, print_every=5000)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1m 30s (- 118m 30s) (5000 1%) 4.8246\n",
            "2m 41s (- 104m 47s) (10000 2%) 4.1858\n",
            "3m 53s (- 99m 41s) (15000 3%) 3.4625\n",
            "5m 6s (- 97m 4s) (20000 5%) 2.7474\n",
            "6m 20s (- 95m 7s) (25000 6%) 2.1563\n",
            "7m 34s (- 93m 25s) (30000 7%) 1.6478\n",
            "8m 49s (- 92m 0s) (35000 8%) 1.2870\n",
            "10m 4s (- 90m 43s) (40000 10%) 0.9819\n",
            "11m 21s (- 89m 32s) (45000 11%) 0.7564\n",
            "12m 37s (- 88m 19s) (50000 12%) 0.6128\n",
            "13m 53s (- 87m 7s) (55000 13%) 0.5175\n",
            "15m 8s (- 85m 50s) (60000 15%) 0.3802\n",
            "16m 24s (- 84m 34s) (65000 16%) 0.2782\n",
            "17m 39s (- 83m 15s) (70000 17%) 0.2285\n",
            "18m 54s (- 81m 58s) (75000 18%) 0.2111\n",
            "20m 10s (- 80m 40s) (80000 20%) 0.1654\n",
            "21m 25s (- 79m 22s) (85000 21%) 0.1477\n",
            "22m 40s (- 78m 7s) (90000 22%) 0.1437\n",
            "23m 57s (- 76m 53s) (95000 23%) 0.1288\n",
            "25m 12s (- 75m 36s) (100000 25%) 0.1335\n",
            "26m 27s (- 74m 20s) (105000 26%) 0.1093\n",
            "27m 43s (- 73m 4s) (110000 27%) 0.1150\n",
            "28m 58s (- 71m 48s) (115000 28%) 0.1066\n",
            "30m 14s (- 70m 32s) (120000 30%) 0.1176\n",
            "31m 30s (- 69m 19s) (125000 31%) 0.1087\n",
            "32m 45s (- 68m 2s) (130000 32%) 0.1069\n",
            "34m 1s (- 66m 46s) (135000 33%) 0.1019\n",
            "35m 17s (- 65m 31s) (140000 35%) 0.0990\n",
            "36m 32s (- 64m 15s) (145000 36%) 0.1046\n",
            "37m 48s (- 63m 1s) (150000 37%) 0.1024\n",
            "39m 4s (- 61m 45s) (155000 38%) 0.0927\n",
            "40m 20s (- 60m 30s) (160000 40%) 0.1006\n",
            "41m 36s (- 59m 14s) (165000 41%) 0.0953\n",
            "42m 51s (- 57m 59s) (170000 42%) 0.0868\n",
            "44m 7s (- 56m 44s) (175000 43%) 0.0912\n",
            "45m 24s (- 55m 29s) (180000 45%) 0.0937\n",
            "46m 40s (- 54m 14s) (185000 46%) 0.0871\n",
            "47m 55s (- 52m 57s) (190000 47%) 0.0868\n",
            "49m 11s (- 51m 42s) (195000 48%) 0.1004\n",
            "50m 27s (- 50m 27s) (200000 50%) 0.0863\n",
            "51m 43s (- 49m 11s) (205000 51%) 0.0904\n",
            "52m 58s (- 47m 55s) (210000 52%) 0.0875\n",
            "54m 13s (- 46m 39s) (215000 53%) 0.0870\n",
            "55m 29s (- 45m 23s) (220000 55%) 0.0837\n",
            "56m 45s (- 44m 8s) (225000 56%) 0.0876\n",
            "58m 0s (- 42m 52s) (230000 57%) 0.0914\n",
            "59m 16s (- 41m 37s) (235000 58%) 0.0873\n",
            "60m 32s (- 40m 21s) (240000 60%) 0.0862\n",
            "61m 47s (- 39m 5s) (245000 61%) 0.0912\n",
            "63m 4s (- 37m 50s) (250000 62%) 0.0944\n",
            "64m 20s (- 36m 34s) (255000 63%) 0.0862\n",
            "65m 36s (- 35m 19s) (260000 65%) 0.0753\n",
            "66m 52s (- 34m 4s) (265000 66%) 0.0760\n",
            "68m 8s (- 32m 48s) (270000 67%) 0.0871\n",
            "69m 24s (- 31m 32s) (275000 68%) 0.0799\n",
            "70m 39s (- 30m 16s) (280000 70%) 0.0812\n",
            "71m 54s (- 29m 0s) (285000 71%) 0.0849\n",
            "73m 9s (- 27m 45s) (290000 72%) 0.0900\n",
            "74m 25s (- 26m 29s) (295000 73%) 0.0838\n",
            "75m 41s (- 25m 13s) (300000 75%) 0.0874\n",
            "76m 56s (- 23m 57s) (305000 76%) 0.0757\n",
            "78m 11s (- 22m 42s) (310000 77%) 0.0835\n",
            "79m 27s (- 21m 26s) (315000 78%) 0.0854\n",
            "80m 42s (- 20m 10s) (320000 80%) 0.0800\n",
            "81m 58s (- 18m 54s) (325000 81%) 0.0817\n",
            "83m 13s (- 17m 39s) (330000 82%) 0.0813\n",
            "84m 29s (- 16m 23s) (335000 83%) 0.0828\n",
            "85m 44s (- 15m 7s) (340000 85%) 0.0854\n",
            "86m 59s (- 13m 52s) (345000 86%) 0.0924\n",
            "88m 15s (- 12m 36s) (350000 87%) 0.0777\n",
            "89m 30s (- 11m 20s) (355000 88%) 0.0733\n",
            "90m 46s (- 10m 5s) (360000 90%) 0.0876\n",
            "92m 2s (- 8m 49s) (365000 91%) 0.0837\n",
            "93m 18s (- 7m 33s) (370000 92%) 0.0857\n",
            "94m 34s (- 6m 18s) (375000 93%) 0.0935\n",
            "95m 50s (- 5m 2s) (380000 95%) 0.0833\n",
            "97m 5s (- 3m 46s) (385000 96%) 0.0807\n",
            "98m 21s (- 2m 31s) (390000 97%) 0.0784\n",
            "99m 36s (- 1m 15s) (395000 98%) 0.0790\n",
            "100m 51s (- 0m 0s) (400000 100%) 0.0846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_umv55x_5MP"
      },
      "source": [
        "torch.save(encoder1.state_dict(), 'en_to_hi_encoder1')\n",
        "torch.save(attn_decoder1.state_dict(), 'en_to_hi_attn_decoder1')"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrByllshFjQW",
        "outputId": "7bc3c538-e957-4f5c-9012-d27e36ef3050"
      },
      "source": [
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "encoder1.load_state_dict(torch.load('en_to_hi_encoder1'))\n",
        "\n",
        "\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "attn_decoder1.load_state_dict(torch.load('en_to_hi_attn_decoder1'))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3786Gu2NFjvM"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHe5HyDeFkYq"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn4SwurYFkzK",
        "outputId": "bbc0a1ec-1f72-4531-d455-8a8483cfc064"
      },
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> Put it where you like .\n",
            "= जहाँ भी रखना है रखदो।\n",
            "< जहाँ भी रखना है रखदो। <EOS>\n",
            "\n",
            "> I'm a good-for-nothing bum .\n",
            "= मैं निकम्मा हूँ।\n",
            "< मैं निकम्मा हूँ। <EOS>\n",
            "\n",
            "> Our class consists of fifty boys .\n",
            "= हमारी कक्षा में पचास लड़के हैं।\n",
            "< हमारी कक्षा में पचास लड़के हैं। <EOS>\n",
            "\n",
            "> Nobody's around .\n",
            "= आसपास कोई नहीं है।\n",
            "< आसपास कोई नहीं है। <EOS>\n",
            "\n",
            "> Unbelievable !\n",
            "= अविश्वसनीय !\n",
            "< अविश्वसनीय ! <EOS>\n",
            "\n",
            "> Who knows ?\n",
            "= कौन जाने ?\n",
            "< किसे पता है ? <EOS>\n",
            "\n",
            "> I took the opportunity to visit Rome .\n",
            "= मैंने रोम जाने के मौका का फ़ायदा उठाया।\n",
            "< मैंने रोम जाने के मौका का फ़ायदा उठाया। <EOS>\n",
            "\n",
            "> He stood up .\n",
            "= वह खड़ा हो गया।\n",
            "< वह खड़ा हो गया। <EOS>\n",
            "\n",
            "> Please speak in a low voice .\n",
            "= कृपया हल्की आवाज़ में बात कीजिए।\n",
            "< कृपया हल्की आवाज़ में बात कीजिए। <EOS>\n",
            "\n",
            "> Remove your shirt and lie down .\n",
            "= अपनी कमीज़ उतार कर लेट जाओ।\n",
            "< अपनी कमीज़ उतार कर लेट जाओ। <EOS>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DJO2rta_5MP",
        "outputId": "cba03740-b5ff-4a5a-e874-961bb52840b0"
      },
      "source": [
        "output_words, attentions = evaluate(\n",
        "    encoder1, attn_decoder1, \"what is your name ?\")\n",
        "output_words"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['आपका', 'नाम', 'क्या', 'है', '?', '<EOS>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIrvWKeU_5MQ",
        "outputId": "42887cbd-55a6-47b9-f30c-49a317dde752"
      },
      "source": [
        "output_words, attentions = evaluate(\n",
        "    encoder1, attn_decoder1,\"what is you\")\n",
        "output_words"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['तुम्हारे', 'पास', 'नहीं', 'है', '<EOS>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mexYxnt_5MQ",
        "outputId": "1d38506d-0da0-45b8-e978-730cd7feee01"
      },
      "source": [
        "output_words, attentions = evaluate(\n",
        "    encoder1, attn_decoder1, \"how are you ?\")\n",
        "output_words"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['तू', 'कैसी', 'है', '?', '<EOS>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_83mruK_5MQ",
        "outputId": "24fbc634-4ca8-44a7-cff0-2d43655fd437"
      },
      "source": [
        "output_words, attentions = evaluate(\n",
        "    encoder1, attn_decoder1, \"is this my car ?\")\n",
        "output_words"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['यह', 'गाड़ी', 'है', 'है', '?', '<EOS>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWTUKXg5_5MR",
        "outputId": "c79b7705-fb88-4701-bd36-a71da050799e"
      },
      "source": [
        "output_words, attentions = evaluate(\n",
        "    encoder1, attn_decoder1, \"I can play piano .\")\n",
        "output_words"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['मैं', 'पियानो', 'बजाना', 'पढ़', 'रहा', 'है।', '<EOS>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2XD8app_5MR",
        "outputId": "9bc4e0bb-9c9e-4285-bb3f-93386198f257"
      },
      "source": [
        "output_words, attentions = evaluate(\n",
        "    encoder1, attn_decoder1, \"I am tired .\")\n",
        "output_words"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['मैं', 'थक', 'गया', 'हूँ।', '<EOS>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wlb7Iog_5MR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4AP6Ccl_5MR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApiUDhAa_5MR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQPfVYAv_5MR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Suh3vWbF_5MT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWxHoJ-w_5MT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05610bbc-c9b1-4c86-f026-d7d98bd02b67"
      },
      "source": [
        "!nvidia-smi "
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jun 28 13:16:13 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   77C    P0    31W /  70W |   1592MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2O7YIFJOGmJF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}